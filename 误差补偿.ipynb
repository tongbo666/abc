{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>准备数据</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>读取数据</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:06:46.575642Z",
     "start_time": "2021-10-20T12:06:44.024789Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import localtime, strftime\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, Flatten, BatchNormalization\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.regularizers import L1L2, L1, L2\n",
    "from tensorflow.keras.callbacks import History, TensorBoard\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>设置tensorflow</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:06:46.710633Z",
     "start_time": "2021-10-20T12:06:46.590645Z"
    }
   },
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>处理数据</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>读取数据</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:06:47.934271Z",
     "start_time": "2021-10-20T12:06:47.871641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特征0</th>\n",
       "      <th>特征1</th>\n",
       "      <th>特征2</th>\n",
       "      <th>特征3</th>\n",
       "      <th>特征4</th>\n",
       "      <th>特征5</th>\n",
       "      <th>特征6</th>\n",
       "      <th>特征7</th>\n",
       "      <th>特征8</th>\n",
       "      <th>特征9</th>\n",
       "      <th>...</th>\n",
       "      <th>特征16</th>\n",
       "      <th>特征17</th>\n",
       "      <th>补偿0</th>\n",
       "      <th>补偿1</th>\n",
       "      <th>补偿2</th>\n",
       "      <th>补偿3</th>\n",
       "      <th>补偿4</th>\n",
       "      <th>补偿5</th>\n",
       "      <th>补偿6</th>\n",
       "      <th>补偿7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.053</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   特征0    特征1   特征2   特征3   特征4   特征5   特征6   特征7   特征8   特征9  ...  特征16  \\\n",
       "0  7.4  0.048  1.19  1.47  0.23  0.54  0.27  5.75  0.65  0.71  ...  0.07   \n",
       "1  3.7    NaN  1.87  0.18  0.94  0.70  0.07  5.20  0.73  0.59  ...  0.91   \n",
       "2  1.2  0.046  1.97  1.17  0.67  0.89  0.60  2.10  0.97  0.14  ...  0.80   \n",
       "3  7.2  0.053  1.17  2.13  0.82  0.18  0.17  5.30  0.27  0.46  ...  0.37   \n",
       "4  1.8  0.021  1.89  0.42  0.20  0.92  0.80  1.60  0.20  0.70  ...  0.50   \n",
       "\n",
       "   特征17   补偿0   补偿1   补偿2   补偿3   补偿4   补偿5   补偿6   补偿7  \n",
       "0  0.62  1.23  0.88  0.73  0.19  1.67  0.36  1.58  1.62  \n",
       "1  0.89  0.99  1.11  0.13  0.18  1.33  0.86  1.22  1.30  \n",
       "2  0.69  1.85  0.13  1.54  1.91  0.63  0.70  1.71  1.57  \n",
       "3  0.37  1.72  0.58  1.03  1.77  0.86  1.65  1.95  1.37  \n",
       "4  0.68  0.83  0.09  0.94  0.49  1.87  1.21  1.53  1.56  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/pic/adjustment.tsv\", delimiter=\"\\t\", skipinitialspace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>处理缺失值</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:06:53.370192Z",
     "start_time": "2021-10-20T12:06:53.357158Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:06:54.844553Z",
     "start_time": "2021-10-20T12:06:54.831025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>补偿0</th>\n",
       "      <th>补偿1</th>\n",
       "      <th>补偿2</th>\n",
       "      <th>补偿3</th>\n",
       "      <th>补偿4</th>\n",
       "      <th>补偿5</th>\n",
       "      <th>补偿6</th>\n",
       "      <th>补偿7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.85</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    补偿0   补偿1   补偿2   补偿3   补偿4   补偿5   补偿6   补偿7\n",
       "0  1.23  0.88  0.73  0.19  1.67  0.36  1.58  1.62\n",
       "2  1.85  0.13  1.54  1.91  0.63  0.70  1.71  1.57\n",
       "3  1.72  0.58  1.03  1.77  0.86  1.65  1.95  1.37\n",
       "4  0.83  0.09  0.94  0.49  1.87  1.21  1.53  1.56\n",
       "5  0.62  0.33  1.13  1.67  1.12  1.23  1.55  1.22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.iloc[:, 0:18]\n",
    "y = data.iloc[:, 18:]\n",
    "x.head(5)\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>划分验证集</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:06:58.245861Z",
     "start_time": "2021-10-20T12:06:58.238898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3488, 18)\n",
      "(873, 18)\n",
      "(3488, 8)\n",
      "(873, 8)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>搭建模型并训练</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>搭建模型</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T12:55:49.410383Z",
     "start_time": "2021-10-18T12:55:49.332372Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(name=\"bn_0\", input_shape=(x.shape[1], )),\n",
    "    Dense(units=2048 * 4, activation=LeakyReLU(), kernel_regularizer=L2(0.2), activity_regularizer=L1(0.1), name=\"dense_1\"),\n",
    "    Dropout(0.3, name=\"dropout_1\"),\n",
    "    Dense(units=y.shape[1], activation=None, name=\"dense_8\")\n",
    "], name=\"adjustment\")\n",
    "model.compile(\n",
    "    loss=Huber(),\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>训练模型</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T12:56:55.444116Z",
     "start_time": "2021-10-18T12:55:52.010013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "  2/109 [..............................] - ETA: 10s - loss: 35.1649 - mae: 1.0060WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_begin` time: 0.0060s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.1950s). Check your callbacks.\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 24.1370 - mae: 0.7782 - val_loss: 11.4370 - val_mae: 0.9299\n",
      "Epoch 2/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.9508 - mae: 1.0282 - val_loss: 4.2711 - val_mae: 1.1599\n",
      "Epoch 3/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 2.8702 - mae: 1.0604 - val_loss: 1.2228 - val_mae: 0.9934\n",
      "Epoch 4/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7421 - mae: 0.9797 - val_loss: 0.6182 - val_mae: 0.9771\n",
      "Epoch 5/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.6114 - mae: 0.9696 - val_loss: 0.6085 - val_mae: 0.9667\n",
      "Epoch 6/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6024 - mae: 0.9593 - val_loss: 0.5991 - val_mae: 0.9564\n",
      "Epoch 7/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5940 - mae: 0.9491 - val_loss: 0.5912 - val_mae: 0.9464\n",
      "Epoch 8/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5860 - mae: 0.9392 - val_loss: 0.5832 - val_mae: 0.9365\n",
      "Epoch 9/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5786 - mae: 0.9293 - val_loss: 0.5773 - val_mae: 0.9268\n",
      "Epoch 10/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5710 - mae: 0.9197 - val_loss: 0.5705 - val_mae: 0.9171\n",
      "Epoch 11/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5647 - mae: 0.9102 - val_loss: 0.5635 - val_mae: 0.9077\n",
      "Epoch 12/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5570 - mae: 0.9008 - val_loss: 0.5567 - val_mae: 0.8983\n",
      "Epoch 13/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5505 - mae: 0.8915 - val_loss: 0.5515 - val_mae: 0.8891\n",
      "Epoch 14/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.5430 - mae: 0.8824 - val_loss: 0.5404 - val_mae: 0.8800\n",
      "Epoch 15/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5366 - mae: 0.8735 - val_loss: 0.5313 - val_mae: 0.8711\n",
      "Epoch 16/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5283 - mae: 0.8647 - val_loss: 0.5282 - val_mae: 0.8623\n",
      "Epoch 17/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.5211 - mae: 0.8560 - val_loss: 0.5196 - val_mae: 0.8537\n",
      "Epoch 18/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5151 - mae: 0.8474 - val_loss: 0.5128 - val_mae: 0.8452\n",
      "Epoch 19/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5083 - mae: 0.8390 - val_loss: 0.5060 - val_mae: 0.8368\n",
      "Epoch 20/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5016 - mae: 0.8307 - val_loss: 0.4999 - val_mae: 0.8285\n",
      "Epoch 21/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4957 - mae: 0.8225 - val_loss: 0.4969 - val_mae: 0.8204\n",
      "Epoch 22/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4882 - mae: 0.8144 - val_loss: 0.4876 - val_mae: 0.8124\n",
      "Epoch 23/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4824 - mae: 0.8065 - val_loss: 0.4796 - val_mae: 0.8045\n",
      "Epoch 24/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4755 - mae: 0.7986 - val_loss: 0.4750 - val_mae: 0.7967\n",
      "Epoch 25/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4683 - mae: 0.7909 - val_loss: 0.4670 - val_mae: 0.7891\n",
      "Epoch 26/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4627 - mae: 0.7833 - val_loss: 0.4603 - val_mae: 0.7815\n",
      "Epoch 27/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4572 - mae: 0.7758 - val_loss: 0.4574 - val_mae: 0.7740\n",
      "Epoch 28/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4512 - mae: 0.7684 - val_loss: 0.4508 - val_mae: 0.7666\n",
      "Epoch 29/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4447 - mae: 0.7611 - val_loss: 0.4424 - val_mae: 0.7593\n",
      "Epoch 30/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4384 - mae: 0.7539 - val_loss: 0.4367 - val_mae: 0.7522\n",
      "Epoch 31/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4321 - mae: 0.7468 - val_loss: 0.4339 - val_mae: 0.7451\n",
      "Epoch 32/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4268 - mae: 0.7398 - val_loss: 0.4255 - val_mae: 0.7381\n",
      "Epoch 33/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4212 - mae: 0.7330 - val_loss: 0.4208 - val_mae: 0.7313\n",
      "Epoch 34/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4155 - mae: 0.7262 - val_loss: 0.4158 - val_mae: 0.7245\n",
      "Epoch 35/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4106 - mae: 0.7196 - val_loss: 0.4104 - val_mae: 0.7179\n",
      "Epoch 36/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4047 - mae: 0.7130 - val_loss: 0.4035 - val_mae: 0.7114\n",
      "Epoch 37/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4004 - mae: 0.7066 - val_loss: 0.3970 - val_mae: 0.7049\n",
      "Epoch 38/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3944 - mae: 0.7002 - val_loss: 0.3912 - val_mae: 0.6986\n",
      "Epoch 39/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3896 - mae: 0.6940 - val_loss: 0.3879 - val_mae: 0.6924\n",
      "Epoch 40/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3842 - mae: 0.6878 - val_loss: 0.3841 - val_mae: 0.6863\n",
      "Epoch 41/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3784 - mae: 0.6817 - val_loss: 0.3766 - val_mae: 0.6803\n",
      "Epoch 42/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3738 - mae: 0.6758 - val_loss: 0.3714 - val_mae: 0.6745\n",
      "Epoch 43/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3691 - mae: 0.6699 - val_loss: 0.3668 - val_mae: 0.6686\n",
      "Epoch 44/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3639 - mae: 0.6641 - val_loss: 0.3616 - val_mae: 0.6629\n",
      "Epoch 45/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3590 - mae: 0.6584 - val_loss: 0.3589 - val_mae: 0.6573\n",
      "Epoch 46/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3541 - mae: 0.6529 - val_loss: 0.3522 - val_mae: 0.6518\n",
      "Epoch 47/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3501 - mae: 0.6473 - val_loss: 0.3485 - val_mae: 0.6464\n",
      "Epoch 48/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3444 - mae: 0.6420 - val_loss: 0.3428 - val_mae: 0.6412\n",
      "Epoch 49/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3403 - mae: 0.6366 - val_loss: 0.3391 - val_mae: 0.6359\n",
      "Epoch 50/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3361 - mae: 0.6314 - val_loss: 0.3336 - val_mae: 0.6309\n",
      "Epoch 51/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3319 - mae: 0.6263 - val_loss: 0.3301 - val_mae: 0.6257\n",
      "Epoch 52/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3271 - mae: 0.6213 - val_loss: 0.3267 - val_mae: 0.6208\n",
      "Epoch 53/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3225 - mae: 0.6163 - val_loss: 0.3220 - val_mae: 0.6159\n",
      "Epoch 54/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3190 - mae: 0.6115 - val_loss: 0.3198 - val_mae: 0.6112\n",
      "Epoch 55/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3148 - mae: 0.6067 - val_loss: 0.3147 - val_mae: 0.6065\n",
      "Epoch 56/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3114 - mae: 0.6020 - val_loss: 0.3094 - val_mae: 0.6021\n",
      "Epoch 57/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3085 - mae: 0.5974 - val_loss: 0.3076 - val_mae: 0.5975\n",
      "Epoch 58/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3034 - mae: 0.5930 - val_loss: 0.3020 - val_mae: 0.5931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2996 - mae: 0.5886 - val_loss: 0.2994 - val_mae: 0.5889\n",
      "Epoch 60/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2964 - mae: 0.5843 - val_loss: 0.2920 - val_mae: 0.5846\n",
      "Epoch 61/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2930 - mae: 0.5800 - val_loss: 0.2936 - val_mae: 0.5803\n",
      "Epoch 62/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2884 - mae: 0.5759 - val_loss: 0.2857 - val_mae: 0.5763\n",
      "Epoch 63/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.2840 - mae: 0.5719 - val_loss: 0.2830 - val_mae: 0.5722\n",
      "Epoch 64/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.2822 - mae: 0.5679 - val_loss: 0.2806 - val_mae: 0.5684\n",
      "Epoch 65/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.2787 - mae: 0.5641 - val_loss: 0.2772 - val_mae: 0.5647\n",
      "Epoch 66/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2752 - mae: 0.5603 - val_loss: 0.2741 - val_mae: 0.5607\n",
      "Epoch 67/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2723 - mae: 0.5565 - val_loss: 0.2726 - val_mae: 0.5567\n",
      "Epoch 68/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2693 - mae: 0.5529 - val_loss: 0.2670 - val_mae: 0.5531\n",
      "Epoch 69/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2656 - mae: 0.5494 - val_loss: 0.2653 - val_mae: 0.5497\n",
      "Epoch 70/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2626 - mae: 0.5459 - val_loss: 0.2595 - val_mae: 0.5463\n",
      "Epoch 71/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2603 - mae: 0.5425 - val_loss: 0.2583 - val_mae: 0.5428\n",
      "Epoch 72/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2563 - mae: 0.5393 - val_loss: 0.2545 - val_mae: 0.5393\n",
      "Epoch 73/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2543 - mae: 0.5361 - val_loss: 0.2520 - val_mae: 0.5364\n",
      "Epoch 74/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2516 - mae: 0.5329 - val_loss: 0.2494 - val_mae: 0.5329\n",
      "Epoch 75/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2480 - mae: 0.5299 - val_loss: 0.2466 - val_mae: 0.5297\n",
      "Epoch 76/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2461 - mae: 0.5269 - val_loss: 0.2449 - val_mae: 0.5269\n",
      "Epoch 77/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2435 - mae: 0.5240 - val_loss: 0.2419 - val_mae: 0.5238\n",
      "Epoch 78/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2409 - mae: 0.5211 - val_loss: 0.2415 - val_mae: 0.5208\n",
      "Epoch 79/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2386 - mae: 0.5183 - val_loss: 0.2378 - val_mae: 0.5179\n",
      "Epoch 80/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2363 - mae: 0.5156 - val_loss: 0.2346 - val_mae: 0.5159\n",
      "Epoch 81/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2337 - mae: 0.5130 - val_loss: 0.2361 - val_mae: 0.5125\n",
      "Epoch 82/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2319 - mae: 0.5105 - val_loss: 0.2327 - val_mae: 0.5101\n",
      "Epoch 83/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2297 - mae: 0.5079 - val_loss: 0.2301 - val_mae: 0.5074\n",
      "Epoch 84/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2275 - mae: 0.5056 - val_loss: 0.2265 - val_mae: 0.5057\n",
      "Epoch 85/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2260 - mae: 0.5031 - val_loss: 0.2249 - val_mae: 0.5033\n",
      "Epoch 86/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2227 - mae: 0.5011 - val_loss: 0.2207 - val_mae: 0.5009\n",
      "Epoch 87/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2202 - mae: 0.4990 - val_loss: 0.2197 - val_mae: 0.4982\n",
      "Epoch 88/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2189 - mae: 0.4968 - val_loss: 0.2194 - val_mae: 0.4960\n",
      "Epoch 89/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2178 - mae: 0.4947 - val_loss: 0.2148 - val_mae: 0.4943\n",
      "Epoch 90/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2145 - mae: 0.4929 - val_loss: 0.2140 - val_mae: 0.4922\n",
      "Epoch 91/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2142 - mae: 0.4909 - val_loss: 0.2128 - val_mae: 0.4906\n",
      "Epoch 92/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2122 - mae: 0.4892 - val_loss: 0.2113 - val_mae: 0.4879\n",
      "Epoch 93/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2101 - mae: 0.4873 - val_loss: 0.2081 - val_mae: 0.4860\n",
      "Epoch 94/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.2084 - mae: 0.4857 - val_loss: 0.2061 - val_mae: 0.4845\n",
      "Epoch 95/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.2064 - mae: 0.4841 - val_loss: 0.2057 - val_mae: 0.4836\n",
      "Epoch 96/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2049 - mae: 0.4826 - val_loss: 0.2050 - val_mae: 0.4811\n",
      "Epoch 97/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2039 - mae: 0.4811 - val_loss: 0.2016 - val_mae: 0.4794\n",
      "Epoch 98/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2018 - mae: 0.4796 - val_loss: 0.2009 - val_mae: 0.4783\n",
      "Epoch 99/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2001 - mae: 0.4783 - val_loss: 0.2001 - val_mae: 0.4776\n",
      "Epoch 100/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1990 - mae: 0.4769 - val_loss: 0.1984 - val_mae: 0.4763\n",
      "Epoch 101/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1979 - mae: 0.4756 - val_loss: 0.1954 - val_mae: 0.4744\n",
      "Epoch 102/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1960 - mae: 0.4745 - val_loss: 0.1944 - val_mae: 0.4737\n",
      "Epoch 103/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1948 - mae: 0.4734 - val_loss: 0.1933 - val_mae: 0.4717\n",
      "Epoch 104/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1934 - mae: 0.4722 - val_loss: 0.1923 - val_mae: 0.4713\n",
      "Epoch 105/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1923 - mae: 0.4711 - val_loss: 0.1917 - val_mae: 0.4689\n",
      "Epoch 106/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1905 - mae: 0.4702 - val_loss: 0.1887 - val_mae: 0.4683\n",
      "Epoch 107/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1894 - mae: 0.4691 - val_loss: 0.1894 - val_mae: 0.4679\n",
      "Epoch 108/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1880 - mae: 0.4682 - val_loss: 0.1847 - val_mae: 0.4664\n",
      "Epoch 109/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1870 - mae: 0.4673 - val_loss: 0.1850 - val_mae: 0.4659\n",
      "Epoch 110/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1858 - mae: 0.4665 - val_loss: 0.1837 - val_mae: 0.4643\n",
      "Epoch 111/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1852 - mae: 0.4657 - val_loss: 0.1821 - val_mae: 0.4646\n",
      "Epoch 112/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1836 - mae: 0.4649 - val_loss: 0.1829 - val_mae: 0.4631\n",
      "Epoch 113/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1820 - mae: 0.4643 - val_loss: 0.1798 - val_mae: 0.4623\n",
      "Epoch 114/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1814 - mae: 0.4634 - val_loss: 0.1814 - val_mae: 0.4610\n",
      "Epoch 115/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1802 - mae: 0.4628 - val_loss: 0.1784 - val_mae: 0.4607\n",
      "Epoch 116/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1791 - mae: 0.4622 - val_loss: 0.1780 - val_mae: 0.4602\n",
      "Epoch 117/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1778 - mae: 0.4615 - val_loss: 0.1759 - val_mae: 0.4604\n",
      "Epoch 118/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1768 - mae: 0.4609 - val_loss: 0.1755 - val_mae: 0.4584\n",
      "Epoch 119/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1759 - mae: 0.4602 - val_loss: 0.1754 - val_mae: 0.4584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1757 - mae: 0.4598 - val_loss: 0.1739 - val_mae: 0.4579\n",
      "Epoch 121/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1743 - mae: 0.4592 - val_loss: 0.1728 - val_mae: 0.4570\n",
      "Epoch 122/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1732 - mae: 0.4588 - val_loss: 0.1711 - val_mae: 0.4571\n",
      "Epoch 123/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1724 - mae: 0.4584 - val_loss: 0.1715 - val_mae: 0.4567\n",
      "Epoch 124/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1717 - mae: 0.4579 - val_loss: 0.1698 - val_mae: 0.4554\n",
      "Epoch 125/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1707 - mae: 0.4574 - val_loss: 0.1695 - val_mae: 0.4557\n",
      "Epoch 126/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1698 - mae: 0.4570 - val_loss: 0.1695 - val_mae: 0.4548\n",
      "Epoch 127/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1699 - mae: 0.4565 - val_loss: 0.1669 - val_mae: 0.4542\n",
      "Epoch 128/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1686 - mae: 0.4562 - val_loss: 0.1667 - val_mae: 0.4536\n",
      "Epoch 129/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1668 - mae: 0.4558 - val_loss: 0.1663 - val_mae: 0.4536\n",
      "Epoch 130/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1676 - mae: 0.4555 - val_loss: 0.1656 - val_mae: 0.4538\n",
      "Epoch 131/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1661 - mae: 0.4553 - val_loss: 0.1655 - val_mae: 0.4530\n",
      "Epoch 132/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1652 - mae: 0.4550 - val_loss: 0.1624 - val_mae: 0.4527\n",
      "Epoch 133/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1645 - mae: 0.4546 - val_loss: 0.1636 - val_mae: 0.4521\n",
      "Epoch 134/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1641 - mae: 0.4545 - val_loss: 0.1614 - val_mae: 0.4519\n",
      "Epoch 135/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1632 - mae: 0.4542 - val_loss: 0.1610 - val_mae: 0.4513\n",
      "Epoch 136/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1627 - mae: 0.4538 - val_loss: 0.1619 - val_mae: 0.4516\n",
      "Epoch 137/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1621 - mae: 0.4538 - val_loss: 0.1591 - val_mae: 0.4514\n",
      "Epoch 138/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1612 - mae: 0.4534 - val_loss: 0.1601 - val_mae: 0.4511\n",
      "Epoch 139/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1603 - mae: 0.4534 - val_loss: 0.1584 - val_mae: 0.4513\n",
      "Epoch 140/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1598 - mae: 0.4532 - val_loss: 0.1576 - val_mae: 0.4508\n",
      "Epoch 141/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1592 - mae: 0.4530 - val_loss: 0.1568 - val_mae: 0.4506\n",
      "Epoch 142/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1587 - mae: 0.4528 - val_loss: 0.1564 - val_mae: 0.4507\n",
      "Epoch 143/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1577 - mae: 0.4527 - val_loss: 0.1556 - val_mae: 0.4502\n",
      "Epoch 144/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1571 - mae: 0.4525 - val_loss: 0.1563 - val_mae: 0.4504\n",
      "Epoch 145/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1566 - mae: 0.4525 - val_loss: 0.1547 - val_mae: 0.4502\n",
      "Epoch 146/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1561 - mae: 0.4523 - val_loss: 0.1545 - val_mae: 0.4504\n",
      "Epoch 147/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1554 - mae: 0.4521 - val_loss: 0.1535 - val_mae: 0.4498\n",
      "Epoch 148/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1554 - mae: 0.4520 - val_loss: 0.1532 - val_mae: 0.4496\n",
      "Epoch 149/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1545 - mae: 0.4520 - val_loss: 0.1528 - val_mae: 0.4500\n",
      "Epoch 150/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1539 - mae: 0.4519 - val_loss: 0.1519 - val_mae: 0.4495\n",
      "Epoch 151/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1534 - mae: 0.4519 - val_loss: 0.1516 - val_mae: 0.4495\n",
      "Epoch 152/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1530 - mae: 0.4517 - val_loss: 0.1509 - val_mae: 0.4495\n",
      "Epoch 153/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1524 - mae: 0.4518 - val_loss: 0.1497 - val_mae: 0.4495\n",
      "Epoch 154/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1518 - mae: 0.4517 - val_loss: 0.1501 - val_mae: 0.4494\n",
      "Epoch 155/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1513 - mae: 0.4515 - val_loss: 0.1499 - val_mae: 0.4494\n",
      "Epoch 156/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1508 - mae: 0.4516 - val_loss: 0.1492 - val_mae: 0.4496\n",
      "Epoch 157/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1504 - mae: 0.4515 - val_loss: 0.1483 - val_mae: 0.4492\n",
      "Epoch 158/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1498 - mae: 0.4515 - val_loss: 0.1482 - val_mae: 0.4493\n",
      "Epoch 159/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1496 - mae: 0.4514 - val_loss: 0.1478 - val_mae: 0.4492\n",
      "Epoch 160/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1490 - mae: 0.4514 - val_loss: 0.1471 - val_mae: 0.4492\n",
      "Epoch 161/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1487 - mae: 0.4514 - val_loss: 0.1466 - val_mae: 0.4491\n",
      "Epoch 162/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1481 - mae: 0.4513 - val_loss: 0.1464 - val_mae: 0.4492\n",
      "Epoch 163/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1478 - mae: 0.4513 - val_loss: 0.1456 - val_mae: 0.4492\n",
      "Epoch 164/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1474 - mae: 0.4513 - val_loss: 0.1453 - val_mae: 0.4491\n",
      "Epoch 165/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1472 - mae: 0.4513 - val_loss: 0.1452 - val_mae: 0.4491\n",
      "Epoch 166/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1469 - mae: 0.4513 - val_loss: 0.1452 - val_mae: 0.4492\n",
      "Epoch 167/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1467 - mae: 0.4513 - val_loss: 0.1448 - val_mae: 0.4491\n",
      "Epoch 168/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1465 - mae: 0.4513 - val_loss: 0.1446 - val_mae: 0.4491\n",
      "Epoch 169/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1463 - mae: 0.4512 - val_loss: 0.1445 - val_mae: 0.4491\n",
      "Epoch 170/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1463 - mae: 0.4512 - val_loss: 0.1446 - val_mae: 0.4491\n",
      "Epoch 171/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1463 - mae: 0.4512 - val_loss: 0.1444 - val_mae: 0.4490\n",
      "Epoch 172/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1462 - mae: 0.4512 - val_loss: 0.1444 - val_mae: 0.4490\n",
      "Epoch 173/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1464 - mae: 0.4512 - val_loss: 0.1447 - val_mae: 0.4490\n",
      "Epoch 174/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1466 - mae: 0.4512 - val_loss: 0.1447 - val_mae: 0.4490\n",
      "Epoch 175/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1466 - mae: 0.4511 - val_loss: 0.1449 - val_mae: 0.4490\n",
      "Epoch 176/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1468 - mae: 0.4511 - val_loss: 0.1451 - val_mae: 0.4490\n",
      "Epoch 177/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1471 - mae: 0.4511 - val_loss: 0.1457 - val_mae: 0.4489\n",
      "Epoch 178/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1475 - mae: 0.4511 - val_loss: 0.1456 - val_mae: 0.4490\n",
      "Epoch 179/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1476 - mae: 0.4511 - val_loss: 0.1461 - val_mae: 0.4489\n",
      "Epoch 180/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1477 - mae: 0.4511 - val_loss: 0.1461 - val_mae: 0.4489\n",
      "Epoch 181/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1478 - mae: 0.4511 - val_loss: 0.1463 - val_mae: 0.4489\n",
      "Epoch 182/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1480 - mae: 0.4511 - val_loss: 0.1461 - val_mae: 0.4489\n",
      "Epoch 183/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1480 - mae: 0.4511 - val_loss: 0.1461 - val_mae: 0.4489\n",
      "Epoch 184/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1480 - mae: 0.4511 - val_loss: 0.1463 - val_mae: 0.4489\n",
      "Epoch 185/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1482 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4489\n",
      "Epoch 186/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 187/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1464 - val_mae: 0.4489\n",
      "Epoch 188/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4489\n",
      "Epoch 189/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 190/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 191/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1463 - val_mae: 0.4490\n",
      "Epoch 192/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 193/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4489\n",
      "Epoch 194/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 195/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1469 - val_mae: 0.4489\n",
      "Epoch 196/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1464 - val_mae: 0.4490\n",
      "Epoch 197/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 198/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 199/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4489\n",
      "Epoch 200/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1464 - val_mae: 0.4490\n",
      "Epoch 201/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4489\n",
      "Epoch 202/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4489\n",
      "Epoch 203/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1463 - val_mae: 0.4490\n",
      "Epoch 204/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 205/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 206/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4489\n",
      "Epoch 207/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4489\n",
      "Epoch 208/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4490\n",
      "Epoch 209/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1464 - val_mae: 0.4490\n",
      "Epoch 210/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 211/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4489\n",
      "Epoch 212/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 213/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 214/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 215/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4489\n",
      "Epoch 216/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 217/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 218/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4489\n",
      "Epoch 219/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 220/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1464 - val_mae: 0.4490\n",
      "Epoch 221/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1483 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4489\n",
      "Epoch 222/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 223/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 224/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4489\n",
      "Epoch 225/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 226/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 227/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1463 - val_mae: 0.4490\n",
      "Epoch 228/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4490\n",
      "Epoch 229/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 230/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4490\n",
      "Epoch 231/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 232/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 233/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4490\n",
      "Epoch 234/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4489\n",
      "Epoch 235/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1465 - val_mae: 0.4490\n",
      "Epoch 236/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 237/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n",
      "Epoch 238/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.4511 - val_loss: 0.1466 - val_mae: 0.4489\n",
      "Epoch 239/240\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1468 - val_mae: 0.4490\n",
      "Epoch 240/240\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1485 - mae: 0.4511 - val_loss: 0.1467 - val_mae: 0.4490\n"
     ]
    }
   ],
   "source": [
    "history: History = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=240,\n",
    "    verbose=1,\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=\"../logs/\" + strftime(\"%Y%m%d-%H%M%S\", localtime()))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ../logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T12:58:50.713750Z",
     "start_time": "2021-10-18T12:58:49.929749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\drzon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\drzon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../logs/adjustments/1\\assets\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"/home/centos/adjustment/1\")     # save_model(model, \"../models/adjustment/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>模型部署</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>部署服务</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -t \\\n",
    "    -p 8501:8501 \\\n",
    "    -v \"/home/centos/adjustment:/models/adjustment\" \\\n",
    "    -e MODEL_NAME=adjustment \\\n",
    "    tensorflow/serving:2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>测试数据</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>读取数据并测试</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:07:08.724340Z",
     "start_time": "2021-10-20T12:07:08.719378Z"
    }
   },
   "outputs": [],
   "source": [
    "data = x_test.values.tolist()\n",
    "headers = {\"content-type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:07:09.569356Z",
     "start_time": "2021-10-20T12:07:09.423095Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    url=\"http://81.70.8.71:8501/v1/models/adjustment:predict\",\n",
    "    data=json.dumps({\"instances\": data}),\n",
    "    headers=headers\n",
    ")\n",
    "if response.status_code != 200:\n",
    "    raise ValueError(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:07:09.952405Z",
     "start_time": "2021-10-20T12:07:09.943407Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.array(json.loads(response.text)[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:07:10.811326Z",
     "start_time": "2021-10-20T12:07:10.806323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2824794860803106\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
